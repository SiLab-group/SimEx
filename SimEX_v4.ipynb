{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f245c784-0372-43cf-847b-9d8b70fde914",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTS\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bca26777",
   "metadata": {},
   "source": [
    "## Part 3: VALIDATOR to test\n",
    "modifier and simulator working in dynamic way, with hardcoded ranges\n",
    "* next step, extract the ranges \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb85f147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DRAFT TEMP FUNCTIONS that will be in validator once they work as intended\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "def get_range(x_values,outliers,delta=0.7):\n",
    "    x_values = np.array(x_values)\n",
    "    relative_max = x_values[-1]\n",
    "    relative_min = x_values[0]\n",
    "    \n",
    "    # Calculate ranges of outliers\n",
    "    outlier_ranges = []\n",
    "\n",
    "    current_range = [outliers[0]]\n",
    "    print('current range: ',current_range)\n",
    "\n",
    "    for i in range(1, len(outliers)):\n",
    "        x_outlier_ranges = []\n",
    "\n",
    "        if outliers[i] == outliers[i-1] + 1:\n",
    "            current_range.append(outliers[i])\n",
    "        else:\n",
    "            \n",
    "            outlier_ranges.append(current_range)\n",
    "            current_range = [outliers[i]]\n",
    "\n",
    "    # Add the last range\n",
    "    outlier_ranges.append(current_range)\n",
    "    print(outlier_ranges)\n",
    "    # Get x value ranges for each outlier range\n",
    "    x_range_max=relative_max\n",
    "    x_range_min = relative_min\n",
    "    for outlier_range in outlier_ranges:\n",
    "        print('\\noutlier_range ',outlier_range)\n",
    "        if np.max(outlier_range)<(np.shape(x_values)[0]-1) and np.min(outlier_range)>0: \n",
    "            delta_low=delta*(x_values[np.min(outlier_range)] - x_values[np.min(outlier_range)-1])\n",
    "            delta_high=delta*np.abs(x_values[np.max(outlier_range)] - x_values[np.max(outlier_range)+1])\n",
    "            x_range_min = np.min(x_values[outlier_range])-delta_low\n",
    "            x_range_max = np.max(x_values[outlier_range])+delta_high\n",
    "            print('I am withing the min max')\n",
    "        elif x_range_max>relative_max or np.max(outlier_range)==(np.shape(x_values)[0]-1):\n",
    "            print('I am at max')\n",
    "            delta_low=delta*(x_values[np.min(outlier_range)] - x_values[np.min(outlier_range)-1])\n",
    "            x_range_min = np.min(x_values[outlier_range])-delta_low\n",
    "            x_range_max=relative_max\n",
    "        elif x_range_min<relative_min or np.min(outlier_range)==0:\n",
    "            print('I am at min')\n",
    "            delta_high=delta*np.abs(x_values[np.max(outlier_range)] - x_values[np.max(outlier_range)+1])\n",
    "            x_range_max = np.max(x_values[outlier_range])+delta_high\n",
    "            x_range_min = relative_min\n",
    "        x_outlier_ranges.append((x_range_min, x_range_max))\n",
    "\n",
    "\n",
    "    print(\"Ranges of outlier x values:\")\n",
    "    for i, x_range in enumerate(x_outlier_ranges):\n",
    "        print(f\"Outlier Range {i+1}: {x_range[0]} to {x_range[1]}\")\n",
    "    \n",
    "    return x_outlier_ranges\n",
    "\n",
    "\n",
    "\n",
    "def curve_fit(mod_x,sim_y, threshold=3):\n",
    "    # Example data\n",
    "    # mod_x = [1.0, 2.4347826086956523, 6.260869565217392, 12.478260869565217, 21.08695652173913, 32.086956521739125, 45.47826086956522, 61.26086956521739, 79.43478260869566, 100.0]\n",
    "    # sim_y = [-18785.46448566434, -22589.28977083527, -13875.22366018544, -8366.169916783167, -10461.393801292468, 5188.58062260236, 76235.86972207189, 197523.09425923007, 435446.98046035116, 1004675.2544642929]\n",
    "\n",
    "    # Reshape the arrays to match HuberRegressor's expectations\n",
    "    x_values = np.array(mod_x)\n",
    "    y_values = np.array(sim_y)\n",
    "\n",
    "    # Create polynomial features\n",
    "    poly = PolynomialFeatures(degree=2)\n",
    "    x_poly = poly.fit_transform(x_values.reshape(-1, 1))\n",
    "\n",
    "    # Fit a polynomial model using HuberRegressor\n",
    "    huber_regressor = HuberRegressor()\n",
    "    huber_regressor.fit(x_poly, y_values)\n",
    "\n",
    "    # Predict y values based on the fitted polynomial model\n",
    "    predicted_y_values = huber_regressor.predict(x_poly)\n",
    "\n",
    "    # Calculate residuals (differences between actual y and predicted y)\n",
    "    residuals = y_values - predicted_y_values\n",
    "\n",
    "    # Calculate the median absolute deviation (MAD) of the residuals\n",
    "    median_absolute_deviation = np.median(np.abs(residuals))\n",
    "\n",
    "    # Define a threshold for outliers (e.g., 3 times MAD)\n",
    "    outlier_threshold = threshold * median_absolute_deviation\n",
    "\n",
    "    # Identify outliers\n",
    "    outliers = np.where(np.abs(residuals) > outlier_threshold)[0]\n",
    "\n",
    "    # Identify points of good fit\n",
    "    good_fit_points = np.where(np.abs(residuals) <= outlier_threshold)[0]\n",
    "\n",
    "    print(\"Outlier indices:\", outliers)\n",
    "    print(\"Good fit indices:\", good_fit_points)\n",
    "\n",
    "    # Plot the original data and the fitted polynomial curve\n",
    "    plt.scatter(x_values, y_values, label='Data points')\n",
    "    plt.plot(x_values, predicted_y_values, color='red', label='Fitted polynomial')\n",
    "    plt.legend()\n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('Y')\n",
    "    plt.title('Fitted Polynomial and Data Points')\n",
    "    plt.show()\n",
    "    return outliers, good_fit_points\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a7bbf0",
   "metadata": {},
   "source": [
    "## PART 4: Main Func: with Modifier.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e14c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from global_settings import fitting_threshold, mdv\n",
    "\n",
    "\n",
    "# import global here: threshold\n",
    "\n",
    "def __init__(self): #i.e. if first iteration\n",
    "    self.iterations = 1\n",
    "    self.total_points = 0\n",
    "    self.total_bad_points = 0\n",
    "    self.range = (mdv[\"domain_min_range\"],mdv[\"domain_max_range\"])  # Initialize the range as a tuple\n",
    "    self.num_points_evaluated = 0  # Initialize num_points_evaluated\n",
    "\n",
    "\n",
    "def fit_curve(x_values,y_values,global_range):\n",
    "    # Assuming you have a function to fit a curve to the data\n",
    "    # Replace the placeholder code below with your curve fitting logic\n",
    "\n",
    "    # standardize    \n",
    "    x_scaler, y_scaler = StandardScaler(), StandardScaler()\n",
    "    x_train = x_scaler.fit_transform(x_values)\n",
    "    y_train = y_scaler.fit_transform(y_values)\n",
    "\n",
    "    # fit model\n",
    "    model = HuberRegressor(epsilon=1)\n",
    "    model.fit(x_train, y_train.ravel())\n",
    "\n",
    "    # Fit curve to the data\n",
    "    fitted_curve = np.polyfit(x_values, y_values, 1)\n",
    "    return fitted_curve\n",
    "\n",
    "def get_unfitting_point(x_values, y_values,fitted_curve,threshold = 0.9):\n",
    "    #extract points that are farther than the threshold\n",
    "    # label them as unfitting points\n",
    "    temp_soln = [1,4,5,6] \n",
    "    unfit_points = [x_values[temp_soln],y_values[temp_soln]]\n",
    "    return unfit_points\n",
    "\n",
    "def get_unfitting_ranges(x_values,sim_y_list,threshold=fitting_threshold):\n",
    "    # apply curve fit to new data\n",
    "    fitted_curve = Validator.fit_curve(x_values,sim_y_list)\n",
    "    # get points of unfit\n",
    "    unfit_points, fit_points = Validator.thresholding(fitted_curve,threshold)\n",
    "\n",
    "    # create ranges from continuous unfit points\n",
    "    if Validator.iterations == 0:\n",
    "        unfit_ranges = [[0,4],[40,50]]\n",
    "\n",
    "    Validator.collect_data(sim_y_list,x_values,unfit_ranges,unfit_points=unfit_points)\n",
    "    # return unfit ranges\n",
    "    Validator.collect_data()\n",
    "    return unfit_ranges\n",
    "\n",
    "def update_history(self, new_total_points, new_range):\n",
    "    self.iterations += 1\n",
    "    self.total_points += new_total_points\n",
    "    self.range = new_range\n",
    "\n",
    "def update_num_points_evaluated(self, points, min_x, max_x):\n",
    "    self.num_points_evaluated = len([(x, y) for x, y in points if min_x <= x <= max_x])\n",
    "\n",
    "def local_exploration_validator_A(x_values, y_values, global_range=[mdv[\"domain_min_range\"],mdv[\"domain_max_range\"]],threshold=fitting_threshold):\n",
    "    # generate fit function \n",
    "    fitted_curve = Validator.fit_curve(x_values, y_values,global_range)\n",
    "    # find misfit points from mod_x_list and sim_y_list (outliers) using threshold from fit function\n",
    "    unfitting_points = Validator.get_unfitting_point(x_values, y_values,fitted_curve,threshold = 0.9)\n",
    "    # generate ranges of misfit points (make it fancy threshold)\n",
    "    unfitting_ranges = Validator.get_unfitting_ranges(unfitting_points)\n",
    "    ## update your history (for each iteration: \n",
    "\n",
    "    # Update history with new values\n",
    "    Validator.update_history(5, 100, (10, 20))  # For example, 5 new iterations, 100 new total points, and new range\n",
    "\n",
    "    # Update num_points_evaluated (self, new_iterations, new_total_points, new_range)\n",
    "    Validator.update_num_points_evaluated(len(x_values), min=global_range[0], max=global_range[1])\n",
    "\n",
    "    # Print updated values\n",
    "    print(f\"Iterations: {Validator.iterations}\")\n",
    "    print(f\"Total Points: {Validator.total_points}\")\n",
    "    print(f\"Range: {Validator.range}\")\n",
    "    print(f\"Num Points Evaluated: {Validator.num_points_evaluated}\")\n",
    "\n",
    "    # iteration, \n",
    "    # total points evaluated (good and misfit), \n",
    "    # points evaluated this iteration (good and misfit), \n",
    "    # number of misfit ranges)\n",
    "\n",
    "    # num_points_input = len(mod_x_list)\n",
    "    # total_points.append(mod_x_list)\n",
    "\n",
    "    # # Get range from previous iteration range generation\n",
    "    # min_x,max_x = range_iteration \n",
    "    # num_points_evaluated = [(x, y) for x, y in total_points if min_x <= x <= max_x]\n",
    "    return unfitting_ranges\n",
    "\n",
    "\n",
    "def validator_controller(mod_x_list,sim_y_list, global_range=[mdv[\"domain_min_range\"],mdv[\"domain_max_range\"]],threshold=fitting_threshold, local_validator=local_exploration_validator_A, do_plot=False):\n",
    "    # gets points mod_x_list, sim_y_list\n",
    "    validator_ranges=Validator.local_exploration_validator_A(mod_x_list,sim_y_list, global_range=[mdv[\"domain_min_range\"],mdv[\"domain_max_range\"]],threshold=fitting_threshold)\n",
    "\n",
    "    # if not first time accessing validator, merge old points with new\n",
    "        # i.e. merge all data points together\n",
    "    return validator_ranges\n",
    "\n",
    "\n",
    "def collect_data(self, sym, mod, ranges, unfit_points):\n",
    "    self.archive_sym.append(sym)\n",
    "    self.archive_mod.append(mod)\n",
    "    # track number of iterations\n",
    "    self.iterations = self.iterations+1\n",
    "    self.total_points = self.total_points+len(mod)\n",
    "    # track number of good/bad points\n",
    "    self.total_unfit_points = self.total_unfit_points+len(mod)\n",
    "\n",
    "def update_statistics(self, new_sym, new_mod):\n",
    "    # track number of points generated from input to get_unfitting_ranges\n",
    "    self.collect_data(new_sym,new_mod)\n",
    "    # track number of unfit intervals i.e. append length of ranges each itteration)\n",
    "    self.history.extend(new_sym)\n",
    "\n",
    "\n",
    "\n",
    "def thresholding(self, threshold):\n",
    "    # Assuming you want to return x values above the threshold\n",
    "    x_values = np.arange(len(self.history))\n",
    "    y_values = np.array(self.history)\n",
    "    above_threshold = x_values[y_values > threshold]\n",
    "    return above_threshold\n",
    "\n",
    "\n",
    "# # Example usage\n",
    "# analyzer = Validator()\n",
    "# data = [1, 2, 3, 4]\n",
    "# analyzer.collect_data(data)\n",
    "# new_data = [5, 6, 7]\n",
    "# analyzer.update_history(new_data)\n",
    "# print(analyzer.history)  # Output: [1, 2, 3, 4, 5, 6, 7]\n",
    "\n",
    "# fitted_curve = analyzer.fit_curve()\n",
    "# print(fitted_curve)  # Output: [slope, intercept]\n",
    "\n",
    "# threshold = 3\n",
    "# above_threshold = analyzer.thresholding(threshold)\n",
    "# print(above_threshold)  # Output: [3, 4, 5, 6]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f801d105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'domain_min_range': 1, 'domain_max_range': 100, 'modifier_incremental_unit': 3, 'modifier_data_point': 10}\n",
      "\n",
      "Modifier controller...\n",
      "  * Interval:  [(1, 100)]\n",
      "     * Iterations within Modifier:  0\n",
      "  * Mod_x shape:    (1, 10)\n",
      "\n",
      "Simulator...\n",
      "  * Sim_y shape:    (10,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[  1.           2.43478261   6.26086957  12.47826087  21.08695652\n  32.08695652  45.47826087  61.26086957  79.43478261 100.        ].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/lorafanda/Documents/Coding/AI/Davide/SimEx/SimEx/SimEX_v4.ipynb Cell 5\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lorafanda/Documents/Coding/AI/Davide/SimEx/SimEx/SimEX_v4.ipynb#W6sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(mod_x) \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(sim_y_list)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lorafanda/Documents/Coding/AI/Davide/SimEx/SimEx/SimEX_v4.ipynb#W6sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39m# Get ranges of unfit points ( IF ANY )\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lorafanda/Documents/Coding/AI/Davide/SimEx/SimEx/SimEX_v4.ipynb#W6sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lorafanda/Documents/Coding/AI/Davide/SimEx/SimEx/SimEX_v4.ipynb#W6sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m \u001b[39m# Run Validator Controller functions\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/lorafanda/Documents/Coding/AI/Davide/SimEx/SimEx/SimEX_v4.ipynb#W6sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m output \u001b[39m=\u001b[39m Validator\u001b[39m.\u001b[39;49mvalidator_controller(mod_x_list\u001b[39m=\u001b[39;49mmod_x,sim_y_list\u001b[39m=\u001b[39;49msim_y_list,threshold\u001b[39m=\u001b[39;49m\u001b[39m0.9\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lorafanda/Documents/Coding/AI/Davide/SimEx/SimEx/SimEX_v4.ipynb#W6sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m \u001b[39m# Example Usage:\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lorafanda/Documents/Coding/AI/Davide/SimEx/SimEx/SimEX_v4.ipynb#W6sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lorafanda/Documents/Coding/AI/Davide/SimEx/SimEx/SimEX_v4.ipynb#W6sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m \u001b[39m# TODO fix error in Validator function\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lorafanda/Documents/Coding/AI/Davide/SimEx/SimEx/SimEX_v4.ipynb#W6sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lorafanda/Documents/Coding/AI/Davide/SimEx/SimEx/SimEX_v4.ipynb#W6sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m \u001b[39m## TODO: Replace for loops with Validator functions that return ranges [(),(),()] format\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lorafanda/Documents/Coding/AI/Davide/SimEx/SimEx/SimEX_v4.ipynb#W6sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m \u001b[39mif\u001b[39;00m x \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m: \n",
      "File \u001b[0;32m~/Documents/Coding/AI/Davide/SimEx/SimEx/Validator.py:103\u001b[0m, in \u001b[0;36mValidator.validator_controller\u001b[0;34m(mod_x_list, sim_y_list, global_range, threshold, local_validator, do_plot)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvalidator_controller\u001b[39m(mod_x_list,sim_y_list, global_range\u001b[39m=\u001b[39m[mdv[\u001b[39m\"\u001b[39m\u001b[39mdomain_min_range\u001b[39m\u001b[39m\"\u001b[39m],mdv[\u001b[39m\"\u001b[39m\u001b[39mdomain_max_range\u001b[39m\u001b[39m\"\u001b[39m]],threshold\u001b[39m=\u001b[39mfitting_threshold, local_validator\u001b[39m=\u001b[39mlocal_exploration_validator_A, do_plot\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    102\u001b[0m     \u001b[39m# gets points mod_x_list, sim_y_list\u001b[39;00m\n\u001b[0;32m--> 103\u001b[0m     validator_ranges\u001b[39m=\u001b[39mValidator\u001b[39m.\u001b[39;49mlocal_exploration_validator_A(mod_x_list,sim_y_list, global_range\u001b[39m=\u001b[39;49m[mdv[\u001b[39m\"\u001b[39;49m\u001b[39mdomain_min_range\u001b[39;49m\u001b[39m\"\u001b[39;49m],mdv[\u001b[39m\"\u001b[39;49m\u001b[39mdomain_max_range\u001b[39;49m\u001b[39m\"\u001b[39;49m]],threshold\u001b[39m=\u001b[39;49mfitting_threshold)\n\u001b[1;32m    105\u001b[0m     \u001b[39m# if not first time accessing validator, merge old points with new\u001b[39;00m\n\u001b[1;32m    106\u001b[0m         \u001b[39m# i.e. merge all data points together\u001b[39;00m\n\u001b[1;32m    107\u001b[0m     \u001b[39mreturn\u001b[39;00m validator_ranges\n",
      "File \u001b[0;32m~/Documents/Coding/AI/Davide/SimEx/SimEx/Validator.py:68\u001b[0m, in \u001b[0;36mValidator.local_exploration_validator_A\u001b[0;34m(x_values, y_values, global_range, threshold)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlocal_exploration_validator_A\u001b[39m(x_values, y_values, global_range\u001b[39m=\u001b[39m[mdv[\u001b[39m\"\u001b[39m\u001b[39mdomain_min_range\u001b[39m\u001b[39m\"\u001b[39m],mdv[\u001b[39m\"\u001b[39m\u001b[39mdomain_max_range\u001b[39m\u001b[39m\"\u001b[39m]],threshold\u001b[39m=\u001b[39mfitting_threshold):\n\u001b[1;32m     67\u001b[0m     \u001b[39m# generate fit function \u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m     fitted_curve \u001b[39m=\u001b[39m Validator\u001b[39m.\u001b[39;49mfit_curve(x_values, y_values,global_range)\n\u001b[1;32m     69\u001b[0m     \u001b[39m# find misfit points from mod_x_list and sim_y_list (outliers) using threshold from fit function\u001b[39;00m\n\u001b[1;32m     70\u001b[0m     unfitting_points \u001b[39m=\u001b[39m Validator\u001b[39m.\u001b[39mget_unfitting_point(x_values, y_values,fitted_curve,threshold \u001b[39m=\u001b[39m \u001b[39m0.9\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Coding/AI/Davide/SimEx/SimEx/Validator.py:25\u001b[0m, in \u001b[0;36mValidator.fit_curve\u001b[0;34m(x_values, y_values, global_range)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit_curve\u001b[39m(x_values,y_values,global_range):\n\u001b[1;32m     20\u001b[0m     \u001b[39m# Assuming you have a function to fit a curve to the data\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     \u001b[39m# Replace the placeholder code below with your curve fitting logic\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \n\u001b[1;32m     23\u001b[0m     \u001b[39m# standardize    \u001b[39;00m\n\u001b[1;32m     24\u001b[0m     x_scaler, y_scaler \u001b[39m=\u001b[39m StandardScaler(), StandardScaler()\n\u001b[0;32m---> 25\u001b[0m     x_train \u001b[39m=\u001b[39m x_scaler\u001b[39m.\u001b[39;49mfit_transform(x_values)\n\u001b[1;32m     26\u001b[0m     y_train \u001b[39m=\u001b[39m y_scaler\u001b[39m.\u001b[39mfit_transform(y_values)\n\u001b[1;32m     28\u001b[0m     \u001b[39m# fit model\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/SimExEnv/lib/python3.10/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/envs/SimExEnv/lib/python3.10/site-packages/sklearn/base.py:915\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[39m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[1;32m    912\u001b[0m \u001b[39m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    914\u001b[0m     \u001b[39m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[0;32m--> 915\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(X, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\u001b[39m.\u001b[39mtransform(X)\n\u001b[1;32m    916\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    917\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m    918\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m~/anaconda3/envs/SimExEnv/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:837\u001b[0m, in \u001b[0;36mStandardScaler.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    835\u001b[0m \u001b[39m# Reset internal state before fitting\u001b[39;00m\n\u001b[1;32m    836\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[0;32m--> 837\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpartial_fit(X, y, sample_weight)\n",
      "File \u001b[0;32m~/anaconda3/envs/SimExEnv/lib/python3.10/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/SimExEnv/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:873\u001b[0m, in \u001b[0;36mStandardScaler.partial_fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    841\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Online computation of mean and std on X for later scaling.\u001b[39;00m\n\u001b[1;32m    842\u001b[0m \n\u001b[1;32m    843\u001b[0m \u001b[39mAll of X is processed as a single batch. This is intended for cases\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    870\u001b[0m \u001b[39m    Fitted scaler.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    872\u001b[0m first_call \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mn_samples_seen_\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 873\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m    874\u001b[0m     X,\n\u001b[1;32m    875\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcsc\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    876\u001b[0m     dtype\u001b[39m=\u001b[39;49mFLOAT_DTYPES,\n\u001b[1;32m    877\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    878\u001b[0m     reset\u001b[39m=\u001b[39;49mfirst_call,\n\u001b[1;32m    879\u001b[0m )\n\u001b[1;32m    880\u001b[0m n_features \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[1;32m    882\u001b[0m \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/SimExEnv/lib/python3.10/site-packages/sklearn/base.py:604\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    602\u001b[0m         out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    603\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 604\u001b[0m     out \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    605\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n\u001b[1;32m    606\u001b[0m     out \u001b[39m=\u001b[39m _check_y(y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n",
      "File \u001b[0;32m~/anaconda3/envs/SimExEnv/lib/python3.10/site-packages/sklearn/utils/validation.py:940\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    938\u001b[0m     \u001b[39m# If input is 1D raise error\u001b[39;00m\n\u001b[1;32m    939\u001b[0m     \u001b[39mif\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 940\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    941\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mExpected 2D array, got 1D array instead:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39marray=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    942\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    943\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    944\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mif it contains a single sample.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[1;32m    945\u001b[0m         )\n\u001b[1;32m    947\u001b[0m \u001b[39mif\u001b[39;00m dtype_numeric \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(array\u001b[39m.\u001b[39mdtype, \u001b[39m\"\u001b[39m\u001b[39mkind\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m array\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39min\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mUSV\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    948\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    949\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdtype=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnumeric\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    950\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    951\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[  1.           2.43478261   6.26086957  12.47826087  21.08695652\n  32.08695652  45.47826087  61.26086957  79.43478261 100.        ].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "# PLACEHOLDER FOR THE MAIN FUNCTION V2\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from global_settings import mdv\n",
    "from Validator import Validator\n",
    "from Modifier import Modifier\n",
    "from Simulator import Simulator\n",
    "\n",
    "print(mdv)\n",
    "#TODO: How to autoreload without restarting kernel (for global vars)\n",
    "# Instantiate mdv values\n",
    "# mdv={\"domain_min_range\":1, \"domain_max_range\":100, \"modifier_incremental_unit\":3, \"modifier_data_point\":10}\n",
    "# Create an instance of the Validator Class\n",
    "validate = Validator\n",
    "modifier = Modifier\n",
    "simulator = Simulator\n",
    "appendedvars=[]\n",
    "\n",
    "mainfunc=True\n",
    "# Initialize interval list\n",
    "interval_lists=[(mdv[\"domain_min_range\"], mdv[\"domain_max_range\"])]\n",
    "x=1\n",
    "while mainfunc==True:\n",
    "\n",
    "    # Run Modifier Controller Function\n",
    "    mod_x_list= modifier.modifier_controller(range_list=interval_lists,local_modifier=modifier.local_modifier_A, do_plot=False)\n",
    "    # appendedvars.append(mod_x_list)\n",
    "\n",
    "    #if data can't be generated:\n",
    "    if mod_x_list == False: # FALSE IF [\"modifier_data_point\"] < mdv[\"modifier_incremental_unit\"]:\n",
    "        print('*   ITERATIONS END HERE   *')\n",
    "        break\n",
    "\n",
    "    # Run Simulator Function\n",
    "    \n",
    "    # for i in range(np.shape(mod_x_list)[0]):\n",
    "\n",
    "    mod_x,sim_y_list = simulator.simulator_controller(mod_x_list,selected_function=simulator.sim_func_A)\n",
    "    # print((mod_x))\n",
    "    # print((sim_y_list))\n",
    "    assert len(mod_x) == len(sim_y_list)\n",
    "    # Get ranges of unfit points ( IF ANY )\n",
    "\n",
    "    # Run Validator Controller functions\n",
    "    output = Validator.validator_controller(mod_x_list=mod_x,sim_y_list=sim_y_list,threshold=0.9)\n",
    "    \n",
    "        \n",
    "    # Example Usage:\n",
    "\n",
    "    # TODO fix error in Validator function\n",
    "    # TODO: Generate Report\n",
    "    # ranges = validate.get_unfitting_ranges(mod_x_list=mod_x,sim_y_list=sim_y_list,threshold=0.9)\n",
    "    # print('these are the ranges of validator\\n',ranges)\n",
    "\n",
    "    ## TODO: Replace for loops with Validator functions that return ranges [(),(),()] format\n",
    "    if x == 1: \n",
    "        ranges = [(0,50),(70,80)]\n",
    "    elif x == 2:\n",
    "        ranges = [(30,50),(70,75)]\n",
    "    elif x==3: \n",
    "        ranges = False\n",
    "    x=x+1\n",
    "    if mod_x_list == False or not ranges: \n",
    "        mainfunc=False\n",
    "        print('The END')\n",
    "    interval_lists = ranges\n",
    "\n",
    "\n",
    "# TODO: \n",
    "# Validator needs to work as a loop within itseft that accepts 3 different sets of points\n",
    "# understand curve fitting\n",
    "# Fix ranges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a72f3ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
