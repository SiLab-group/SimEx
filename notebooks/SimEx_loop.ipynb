{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# SimEX Loop\n",
    "We will be asked to create a \"coach\" loop that organize the training of a controller, which will do the following \n",
    "\n",
    "The following is pseudo-code which shall not necessarily represent the real method signatures, but shall indicate the flow of logic, presenting where which information is used and consumed.  \n",
    "```bash\n",
    "init trainingData \n",
    "\n",
    "counter = 0 \n",
    "\n",
    "newTrainingData = {} \n",
    "\n",
    "Do \n",
    "\n",
    "counter++ \n",
    "\n",
    "trainingData = trainingData + newTrainingData \n",
    "\n",
    "controller.doTraining(trainingData) \n",
    "\n",
    "PathtoCSV= runSimEx(controller) //creates new csv outputs \n",
    " - Seems to only be the simulator? providing new function in the simulator as parameter (retrained model?) \n",
    "\n",
    "newTrainingData = checkPerformance(PathToReference, PathToCSV).  \n",
    "\n",
    "// method provide by Martin, reading csv output from simex, but is a simple loop testing for fixed areas if their performance is higher or lower than the reference (computing the value of the provide polynom, identifiyable via the intervals in the csv) and if the currentPerfomance is worse than reference add datapoints for new training data (approximate at least reference values as targets)).   \n",
    "\n",
    "while(newTrainingData !={} AND counter<MaxIteration)\n",
    "```\n",
    "methods in need to be provided by HR side, but they need our help to give them a structure to work in \n",
    "\n",
    "Note, with this loop you can theoretically implement zero learning (from untrained to hero automatically \n",
    "\n",
    "Note 2: this loops enable the interesting question, when do we stop learning, even though results are not perfect, e.g. when we have to acknowledge given available actions, we cannot solve the problem (as for the moment, what is \"learned\" is the action-selection, while primitive actions are pre-defined. I.e. when the set of actions is not sufficient no learning can be successful, an alternative when to stopp before I overfit... * all of this are interesting research questions (for later work) "
   ],
   "id": "a3fa0b1fb9f669c4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T09:38:11.072860Z",
     "start_time": "2024-09-02T09:38:11.047288Z"
    }
   },
   "cell_type": "code",
   "source": "print(\"hell\")",
   "id": "c6ba8d3d9fd47bc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hell\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T08:07:45.916787Z",
     "start_time": "2024-09-06T08:07:44.991513Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import subprocess\n",
    "import pandas as pd\n",
    "import os\n",
    "os.environ['INSTANCE_NAME'] = 'LOOP_script'\n",
    "from global_settings import SimexSettings\n",
    "script_dir = os.path.abspath('')\n",
    "results_dir = os.path.join(script_dir, f'{SimexSettings.results_dir}')\n",
    "\n",
    "if not os.path.isdir(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "\n",
    "from DLASIUT_find_best_scenarios import automatic_performance\n",
    "\n",
    "scripts = ['sumo_novsl_run.py', 'sumo_vsl_run.py']\n",
    "print(\"start\")\n",
    "files = []\n",
    "for script in scripts:\n",
    "    cmd = ['python3', script]\n",
    "    lines = subprocess.run(cmd,stdout=subprocess.PIPE).stdout.splitlines()\n",
    "    print(f\" LINES: {lines}\")\n",
    "    baseline_file = None\n",
    "    for line in lines:\n",
    "        output = \"{}\".format(line.rstrip().decode(\"utf-8\"))\n",
    "        if 'simex_output' in output:\n",
    "            files.append(output)\n",
    "    \n",
    "     # collect name of the csv file\n",
    "    if len(files) == 2:\n",
    "        df_baseline = pd.read_csv(files[1])\n",
    "        df_control = pd.read_csv(files[0])\n",
    "        # Main Function receives np.arrays\n",
    "        dataset_baseline = df_baseline.to_numpy()\n",
    "        dataset_control = df_control.to_numpy()\n",
    "\n",
    "        # Run martin script on the csv files\n",
    "        _incremnet_step_for_x = 10\n",
    "        _max_order_of_polynom = 9\n",
    "        _tolerance_in_diffrence = 12\n",
    "        results = automatic_performance(dataset_baseline, dataset_control, incremnet_step_for_x=_incremnet_step_for_x,\n",
    "                                        max_order_of_polynom=_max_order_of_polynom,\n",
    "                                        tolerance_in_diffrence=_tolerance_in_diffrence)\n",
    "        print(f\"Results: {results}\")      "
   ],
   "id": "35ffc661c2799456",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/amy/tmp/repos/SimEx/notebooks/sumo_novsl_run.py\", line 12, in <module>\n",
      "    from global_settings import simexSettings, mds, timestamp, fs\n",
      "ImportError: cannot import name 'simexSettings' from 'global_settings' (/home/amy/tmp/repos/SimEx/notebooks/global_settings.py)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " LINES: []\n",
      " LINES: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/amy/tmp/repos/SimEx/notebooks/sumo_vsl_run.py\", line 13, in <module>\n",
      "    from global_settings import simexSettings, mds, timestamp, fs\n",
      "ImportError: cannot import name 'simexSettings' from 'global_settings' (/home/amy/tmp/repos/SimEx/notebooks/global_settings.py)\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T06:51:46.777886Z",
     "start_time": "2024-09-03T06:51:45.380485Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import os\n",
    "os.environ['INSTANCE_NAME'] = 'LOOP_script'\n",
    "from global_settings import simexSettings\n",
    "script_dir = os.path.abspath('')\n",
    "results_dir = os.path.join(script_dir, f'{simexSettings[\"results_dir\"]}')\n",
    "\n",
    "if not os.path.isdir(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "\n",
    "from DLASIUT_find_best_scenarios import automatic_performance\n",
    "files = ['/home/amy/tmp/repos/SimEx/notebooks/results_dir_NOVSL_script-20240902-113858/simex_output-NOVSL_script-20240902-113858.csv','/home/amy/tmp/repos/SimEx/notebooks/results_dir_VSL_script-20240902-120605/simex_output-VSL_script-20240902-120605.csv']\n",
    "print(f\"Files {files}\")\n",
    "df_baseline = pd.read_csv(files[1])\n",
    "df_control = pd.read_csv(files[0])\n",
    "# Main Function receives np.arrays\n",
    "dataset_baseline = df_baseline.to_numpy()\n",
    "dataset_control = df_control.to_numpy()\n",
    "\n",
    "# Run martin script on the csv files\n",
    "_incremnet_step_for_x = 10\n",
    "_max_order_of_polynom = 9\n",
    "_tolerance_in_diffrence = 12\n",
    "results = automatic_performance(dataset_baseline, dataset_control, incremnet_step_for_x=_incremnet_step_for_x,\n",
    "                                        max_order_of_polynom=_max_order_of_polynom,\n",
    "                                        tolerance_in_diffrence=_tolerance_in_diffrence)\n",
    "print(f\"Results: {results}\") "
   ],
   "id": "3c43ac3732fe015d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files ['/home/amy/tmp/repos/SimEx/notebooks/results_dir_NOVSL_script-20240902-113858/simex_output-NOVSL_script-20240902-113858.csv', '/home/amy/tmp/repos/SimEx/notebooks/results_dir_VSL_script-20240902-120605/simex_output-VSL_script-20240902-120605.csv']\n",
      "[[2.50e+03 2.51e+03 0.00e+00]\n",
      " [2.51e+03 2.52e+03 0.00e+00]\n",
      " [2.52e+03 2.53e+03 0.00e+00]\n",
      " [2.53e+03 2.54e+03 0.00e+00]\n",
      " [2.54e+03 2.55e+03 0.00e+00]\n",
      " [2.55e+03 2.56e+03 0.00e+00]\n",
      " [2.56e+03 2.57e+03 0.00e+00]\n",
      " [2.57e+03 2.58e+03 0.00e+00]\n",
      " [2.58e+03 2.59e+03 0.00e+00]\n",
      " [2.59e+03 2.60e+03 0.00e+00]\n",
      " [2.60e+03 2.61e+03 0.00e+00]\n",
      " [2.61e+03 2.62e+03 0.00e+00]\n",
      " [2.62e+03 2.63e+03 0.00e+00]\n",
      " [2.63e+03 2.64e+03 0.00e+00]\n",
      " [2.64e+03 2.65e+03 0.00e+00]\n",
      " [2.65e+03 2.66e+03 0.00e+00]\n",
      " [2.66e+03 2.67e+03 0.00e+00]\n",
      " [2.67e+03 2.68e+03 0.00e+00]\n",
      " [2.68e+03 2.69e+03 0.00e+00]\n",
      " [2.69e+03 2.70e+03 0.00e+00]\n",
      " [2.70e+03 2.71e+03 0.00e+00]\n",
      " [2.71e+03 2.72e+03 0.00e+00]\n",
      " [2.72e+03 2.73e+03 0.00e+00]\n",
      " [2.73e+03 2.74e+03 0.00e+00]\n",
      " [2.74e+03 2.75e+03 0.00e+00]\n",
      " [2.75e+03 2.76e+03 0.00e+00]\n",
      " [2.76e+03 2.77e+03 0.00e+00]\n",
      " [2.77e+03 2.78e+03 0.00e+00]\n",
      " [2.78e+03 2.79e+03 0.00e+00]\n",
      " [2.79e+03 2.80e+03 0.00e+00]\n",
      " [2.80e+03 2.81e+03 0.00e+00]\n",
      " [2.81e+03 2.82e+03 0.00e+00]\n",
      " [2.82e+03 2.83e+03 0.00e+00]\n",
      " [2.83e+03 2.84e+03 0.00e+00]\n",
      " [2.84e+03 2.85e+03 0.00e+00]\n",
      " [2.85e+03 2.86e+03 0.00e+00]\n",
      " [2.86e+03 2.87e+03 0.00e+00]\n",
      " [2.87e+03 2.88e+03 0.00e+00]\n",
      " [2.88e+03 2.89e+03 0.00e+00]\n",
      " [2.89e+03 2.90e+03 0.00e+00]\n",
      " [2.90e+03 2.91e+03 0.00e+00]\n",
      " [2.91e+03 2.92e+03 0.00e+00]\n",
      " [2.92e+03 2.93e+03 0.00e+00]\n",
      " [2.93e+03 2.94e+03 0.00e+00]\n",
      " [2.94e+03 2.95e+03 0.00e+00]\n",
      " [2.95e+03 2.96e+03 0.00e+00]\n",
      " [2.96e+03 2.97e+03 0.00e+00]\n",
      " [2.97e+03 2.98e+03 0.00e+00]\n",
      " [2.98e+03 2.99e+03 0.00e+00]\n",
      " [2.99e+03 3.00e+03 0.00e+00]\n",
      " [3.00e+03 3.01e+03 0.00e+00]\n",
      " [3.01e+03 3.02e+03 0.00e+00]\n",
      " [3.02e+03 3.03e+03 0.00e+00]\n",
      " [3.03e+03 3.04e+03 0.00e+00]\n",
      " [3.04e+03 3.05e+03 0.00e+00]\n",
      " [3.05e+03 3.06e+03 0.00e+00]\n",
      " [3.06e+03 3.07e+03 0.00e+00]\n",
      " [3.07e+03 3.08e+03 0.00e+00]\n",
      " [3.08e+03 3.09e+03 0.00e+00]\n",
      " [3.09e+03 3.10e+03 0.00e+00]\n",
      " [3.10e+03 3.11e+03 0.00e+00]\n",
      " [3.11e+03 3.12e+03 0.00e+00]\n",
      " [3.12e+03 3.13e+03 0.00e+00]\n",
      " [3.13e+03 3.14e+03 0.00e+00]\n",
      " [3.14e+03 3.15e+03 0.00e+00]\n",
      " [3.15e+03 3.16e+03 0.00e+00]\n",
      " [3.16e+03 3.17e+03 0.00e+00]\n",
      " [3.17e+03 3.18e+03 0.00e+00]\n",
      " [3.18e+03 3.19e+03 0.00e+00]\n",
      " [3.19e+03 3.20e+03 0.00e+00]\n",
      " [3.20e+03 3.21e+03 0.00e+00]\n",
      " [3.21e+03 3.22e+03 0.00e+00]\n",
      " [3.22e+03 3.23e+03 0.00e+00]\n",
      " [3.23e+03 3.24e+03 0.00e+00]\n",
      " [3.24e+03 3.25e+03 0.00e+00]\n",
      " [3.25e+03 3.26e+03 0.00e+00]\n",
      " [3.26e+03 3.27e+03 0.00e+00]\n",
      " [3.27e+03 3.28e+03 0.00e+00]\n",
      " [3.28e+03 3.29e+03 0.00e+00]\n",
      " [3.29e+03 3.30e+03 0.00e+00]\n",
      " [3.30e+03 3.31e+03 0.00e+00]\n",
      " [3.31e+03 3.32e+03 0.00e+00]\n",
      " [3.32e+03 3.33e+03 0.00e+00]\n",
      " [3.33e+03 3.34e+03 0.00e+00]\n",
      " [3.34e+03 3.35e+03 0.00e+00]\n",
      " [3.35e+03 3.36e+03 0.00e+00]\n",
      " [3.36e+03 3.37e+03 0.00e+00]\n",
      " [3.37e+03 3.38e+03 0.00e+00]\n",
      " [3.38e+03 3.39e+03 0.00e+00]\n",
      " [3.39e+03 3.40e+03 0.00e+00]\n",
      " [3.40e+03 3.41e+03 0.00e+00]\n",
      " [3.41e+03 3.42e+03 0.00e+00]\n",
      " [3.42e+03 3.43e+03 0.00e+00]\n",
      " [3.43e+03 3.44e+03 0.00e+00]\n",
      " [3.44e+03 3.45e+03 0.00e+00]\n",
      " [3.45e+03 3.46e+03 0.00e+00]\n",
      " [3.46e+03 3.47e+03 0.00e+00]\n",
      " [3.47e+03 3.48e+03 0.00e+00]\n",
      " [3.48e+03 3.49e+03 0.00e+00]\n",
      " [3.49e+03 3.50e+03 0.00e+00]\n",
      " [3.50e+03 3.51e+03 0.00e+00]\n",
      " [3.51e+03 3.52e+03 0.00e+00]\n",
      " [3.52e+03 3.53e+03 0.00e+00]\n",
      " [3.53e+03 3.54e+03 0.00e+00]\n",
      " [3.54e+03 3.55e+03 0.00e+00]\n",
      " [3.55e+03 3.56e+03 0.00e+00]\n",
      " [3.56e+03 3.57e+03 0.00e+00]\n",
      " [3.57e+03 3.58e+03 0.00e+00]\n",
      " [3.58e+03 3.59e+03 0.00e+00]\n",
      " [3.59e+03 3.60e+03 0.00e+00]\n",
      " [3.60e+03 3.61e+03 0.00e+00]\n",
      " [3.61e+03 3.62e+03 0.00e+00]\n",
      " [3.62e+03 3.63e+03 0.00e+00]\n",
      " [3.63e+03 3.64e+03 0.00e+00]\n",
      " [3.64e+03 3.65e+03 0.00e+00]\n",
      " [3.65e+03 3.66e+03 0.00e+00]\n",
      " [3.66e+03 3.67e+03 0.00e+00]\n",
      " [3.67e+03 3.68e+03 1.00e+00]\n",
      " [3.68e+03 3.69e+03 0.00e+00]\n",
      " [3.69e+03 3.70e+03 0.00e+00]\n",
      " [3.70e+03 3.71e+03 0.00e+00]\n",
      " [3.71e+03 3.72e+03 0.00e+00]\n",
      " [3.72e+03 3.73e+03 0.00e+00]\n",
      " [3.73e+03 3.74e+03 0.00e+00]\n",
      " [3.74e+03 3.75e+03 0.00e+00]\n",
      " [3.75e+03 3.76e+03 0.00e+00]\n",
      " [3.76e+03 3.77e+03 0.00e+00]\n",
      " [3.77e+03 3.78e+03 0.00e+00]\n",
      " [3.78e+03 3.79e+03 0.00e+00]\n",
      " [3.79e+03 3.80e+03 0.00e+00]\n",
      " [3.80e+03 3.81e+03 0.00e+00]\n",
      " [3.81e+03 3.82e+03 0.00e+00]\n",
      " [3.82e+03 3.83e+03 0.00e+00]\n",
      " [3.83e+03 3.84e+03 0.00e+00]\n",
      " [3.84e+03 3.85e+03 0.00e+00]\n",
      " [3.85e+03 3.86e+03 0.00e+00]\n",
      " [3.86e+03 3.87e+03 0.00e+00]\n",
      " [3.87e+03 3.88e+03 0.00e+00]\n",
      " [3.88e+03 3.89e+03 0.00e+00]\n",
      " [3.89e+03 3.90e+03 0.00e+00]\n",
      " [3.90e+03 3.91e+03 0.00e+00]\n",
      " [3.91e+03 3.92e+03 0.00e+00]\n",
      " [3.92e+03 3.93e+03 0.00e+00]\n",
      " [3.93e+03 3.94e+03 0.00e+00]\n",
      " [3.94e+03 3.95e+03 0.00e+00]\n",
      " [3.95e+03 3.96e+03 0.00e+00]\n",
      " [3.96e+03 3.97e+03 0.00e+00]\n",
      " [3.97e+03 3.98e+03 0.00e+00]\n",
      " [3.98e+03 3.99e+03 0.00e+00]\n",
      " [3.99e+03 4.00e+03 0.00e+00]]\n",
      "[[3670.0, 3680.0]]\n",
      "Results: [[3670.0, 3680.0]]\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T19:11:17.487169Z",
     "start_time": "2024-09-05T19:11:17.463491Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def run_simex(simulator_function, instance_name):    \n",
    "    # IMPORT LIBRARIES\n",
    "    import os\n",
    "    import argparse\n",
    "    import numpy as np\n",
    "    # Set instance name\n",
    "    # os.environ['INSTANCE_NAME'] = instance_name\n",
    "    \n",
    "    from global_settings import simexSettings, mds, timestamp, fs\n",
    "    resultdir = f\"results_dir_{instance_name}-{timestamp}\"\n",
    "    # Create directory for the results\n",
    "    script_dir = os.path.abspath('')\n",
    "    results_dir = os.path.join(script_dir, resultdir)\n",
    "    \n",
    "    if not os.path.isdir(results_dir):\n",
    "        os.makedirs(results_dir)\n",
    "    \n",
    "    from components_configuration import components\n",
    "    from validator_controller import ValidatorController\n",
    "    from modifier_controller import ModifierController\n",
    "    from simulator_controller import SimulatorController\n",
    "    from logger_utils import Logger\n",
    "    \n",
    "    import pickle\n",
    "    import datetime\n",
    "    \n",
    "    def save_object(obj, filename):\n",
    "        with open(filename, 'wb') as outp:  # Overwrites any existing file.\n",
    "            pickle.dump(obj, outp, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    \n",
    "    validator_controller_vsl = ValidatorController()\n",
    "    logger = Logger()\n",
    "    logger_main_arguments = {}\n",
    "    is_main_func = True\n",
    "    # Initialize interval list for the first iteration\n",
    "    \n",
    "    \n",
    "    intervals_list = [[mds['domain_min_interval'], mds['domain_max_interval']]]\n",
    "    # Timestamp for the validator pickle file\n",
    "    count = 0\n",
    "    \n",
    "    while is_main_func:\n",
    "        # Calls Modifier Controller\n",
    "        # NOTE: intervals_list type is set to np.int64 due to: https://github.com/numpy/numpy/issues/8433 on windows\n",
    "        mod_outcome = ModifierController.control(intervals_list=intervals_list, selected_modifier=components['modifierA'],\n",
    "                                                 do_plot=simexSettings['do_plot'])\n",
    "        mod_x_list = mod_outcome[0]\n",
    "        checked_intervals = mod_outcome[1]\n",
    "        print(\"MAIN mod outcome\", mod_outcome)\n",
    "    \n",
    "        # breaks loop if iterations end by granularity reached\n",
    "        if not mod_x_list:  # FALSE IF ['modifier_data_point'] < mdv['modifier_incremental_unit']:\n",
    "            logger_main_arguments['log_contex'] = 'overall MAIN stats'\n",
    "            logger_main_arguments['main_status'] = 'no generated points'\n",
    "            logger_main_arguments['remaining_unfit_intervals'] = checked_intervals\n",
    "            logger.log_main(logger_main_arguments)\n",
    "            break\n",
    "    \n",
    "        # Calls Simulator\n",
    "        mod_x, sim_y_list = SimulatorController.simulate_parallel(mod_x_list, selected_simulator=simulator_function)\n",
    "        print(f\"MODX {mod_x} and sim_y_list {sim_y_list}\")\n",
    "        assert len(mod_x) == len(sim_y_list)\n",
    "    \n",
    "        print(\"MAIN modx\", mod_x)\n",
    "    \n",
    "        # Calls Validator controller\n",
    "        intervals_list = validator_controller_vsl.validate(mod_x_list=np.array(mod_x), sim_y_list=np.array(sim_y_list),\n",
    "                                                           selected_validator=components['validator'],\n",
    "                                                           global_interval=[mds[\"domain_min_interval\"],\n",
    "                                                                            mds[\"domain_max_interval\"]])\n",
    "        print(\"MAIN interval list from VAL:\", intervals_list)\n",
    "        # Loop number ( Loop-1,Loop-2..etc)\n",
    "        count += 1\n",
    "        save_object(validator_controller_vsl, os.path.join(results_dir, f\"vc_vsl_loop-{count}-{timestamp}.pkl\"))\n",
    "    \n",
    "        # Updates interval_list to new range output from validator controller\n",
    "        # No more unfit intervals -> write MAIN log\n",
    "        if not intervals_list:\n",
    "            is_main_func = False\n",
    "            logger_main_arguments['log_contex'] = 'overall MAIN stats'\n",
    "            logger_main_arguments['main_status'] = 'no unfit intervals'\n",
    "            logger.log_main(logger_main_arguments)\n",
    "    \n",
    "    # MAIN cycle completed/interrupted -> write OVERALL statistics\n",
    "    logger_main_arguments['log_contex'] = 'Overall Stats'\n",
    "    logger_main_arguments['main_status'] = 'end cycle'\n",
    "    logger.log_main(logger_main_arguments)\n",
    "    \n",
    "    # Save data for the last plot located in logger object\n",
    "    save_object(logger.all_fit_intervals_data,os.path.join(results_dir,f\"logger-vsl_script-fitted_intervals-{timestamp}.pkl\"))\n",
    "    # If not empty\n",
    "    if logger.remaining_unfit_intervals:\n",
    "        save_object(logger.remaining_unfit_intervals,os.path.join(results_dir,f\"logger-vsl_script-unfitted_intervals-{timestamp}.pkl\"))\n",
    "    # print(f\"Logger object saved with timestamp {timestamp}\")\n",
    "    file = f\"{fs['csv_filename']}-{timestamp}.csv\"\n",
    "    file_path = os.path.join(results_dir,file)\n",
    "    print(f\"{file_path}\")\n",
    "    return file_path"
   ],
   "id": "326c72eb7ec17a01",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T19:11:21.026033Z",
     "start_time": "2024-09-05T19:11:19.291341Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import subprocess\n",
    "import pandas as pd\n",
    "# import os\n",
    "# os.environ['INSTANCE_NAME'] = 'LOOP_script'\n",
    "# from global_settings import simexSettings\n",
    "# script_dir = os.path.abspath('')\n",
    "# results_dir = os.path.join(script_dir, f'{simexSettings[\"results_dir\"]}')\n",
    "# \n",
    "# if not os.path.isdir(results_dir):\n",
    "#     os.makedirs(results_dir)\n",
    "\n",
    "from DLASIUT_find_best_scenarios import automatic_performance\n",
    "# from components_configuration import components\n",
    "from simulator import Simulator\n",
    "\n",
    "# scripts = [ 'sumo_novsl_run.py', 'sumo_vsl_run.py']\n",
    "# # Run scripts\n",
    "# def run_script(script) -> str:\n",
    "#     cmd = ['python3', script[0]]\n",
    "#     lines = subprocess.run(cmd,stdout=subprocess.PIPE).stdout.splitlines()\n",
    "#     print(f\" LINES: {lines}\")\n",
    "#     baseline_file = None\n",
    "#     for line in lines:\n",
    "#         output = \"{}\".format(line.rstrip().decode(\"utf-8\"))\n",
    "#         if 'simex_output' in output:\n",
    "#             baseline_file =  output\n",
    "#     return baseline_file\n",
    "\n",
    "# Run baseline NOVSL case\n",
    "\n",
    "# Rewrite function to accept different types of input data and different simulator function\n",
    "os.environ['INSTANCE_NAME'] = 'NOVSL_base'\n",
    "base_file = run_simex(simulator_function=Simulator.sumo_simulator_novsl, instance_name='NOVSL_base_case')\n",
    "# collect name of the csv file\n",
    "if base_file:\n",
    "    df_baseline = pd.read_csv(base_file)\n",
    "    # Main Function receives np.arrays\n",
    "    dataset_baseline = df_baseline.to_numpy()\n",
    "    counter = 0\n",
    "    MaxIteration = 10\n",
    "    newTrainingData = []\n",
    "    while True:\n",
    "        counter +=1\n",
    "        # trainingData = trainingData + newTrainingData \n",
    "\n",
    "        # Insert training of the controller\n",
    "        # controller.doTraining(trainingData)\n",
    "        # Run simex for the retrained controller replace components['']\n",
    "        os.environ['INSTANCE_NAME'] = f'VSL_{counter}'\n",
    "        control_file = run_simex(simulator_function=Simulator.sumo_simulator_vsl, instance_name='VSL')\n",
    "        df_control = pd.read_csv(control_file)\n",
    "        dataset_control = df_control.to_numpy()\n",
    "        # Run martin script on the csv files\n",
    "        _incremnet_step_for_x = 10\n",
    "        _max_order_of_polynom = 9\n",
    "        _tolerance_in_diffrence=12\n",
    "        newTrainingData = automatic_performance(dataset_baseline,dataset_control,incremnet_step_for_x=_incremnet_step_for_x,max_order_of_polynom=_max_order_of_polynom,tolerance_in_diffrence=_tolerance_in_diffrence)\n",
    "        print(results)\n",
    "        if not newTrainingData and counter<MaxIteration:\n",
    "            break\n",
    "\n"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'INSTANCE_NAME'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 14\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mDLASIUT_find_best_scenarios\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m automatic_performance\n\u001B[1;32m     13\u001B[0m \u001B[38;5;66;03m# from components_configuration import components\u001B[39;00m\n\u001B[0;32m---> 14\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msimulator\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Simulator\n\u001B[1;32m     16\u001B[0m \u001B[38;5;66;03m# scripts = [ 'sumo_novsl_run.py', 'sumo_vsl_run.py']\u001B[39;00m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;66;03m# # Run scripts\u001B[39;00m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;66;03m# def run_script(script) -> str:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     30\u001B[0m \n\u001B[1;32m     31\u001B[0m \u001B[38;5;66;03m# Rewrite function to accept different types of input data and different simulator function\u001B[39;00m\n\u001B[1;32m     32\u001B[0m os\u001B[38;5;241m.\u001B[39menviron[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mINSTANCE_NAME\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNOVSL_base\u001B[39m\u001B[38;5;124m'\u001B[39m\n",
      "File \u001B[0;32m~/tmp/repos/SimEx/notebooks/simulator.py:7\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01msim_get_set\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01msim\u001B[39;00m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mvsl_controller\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mVSL\u001B[39;00m\n\u001B[0;32m----> 7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mglobal_settings\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m sumovsls\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mSimulator\u001B[39;00m:\n\u001B[1;32m     11\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msim_func_A\u001B[39m(x):\n\u001B[1;32m     12\u001B[0m         \u001B[38;5;66;03m# print('\\nthis should be a single point: ',x)\u001B[39;00m\n",
      "File \u001B[0;32m~/tmp/repos/SimEx/notebooks/global_settings.py:39\u001B[0m\n\u001B[1;32m     17\u001B[0m mds \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdomain_min_interval\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m2500\u001B[39m,\n\u001B[1;32m     18\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdomain_max_interval\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m4000\u001B[39m,\n\u001B[1;32m     19\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodifier_incremental_unit\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m25\u001B[39m,  \u001B[38;5;66;03m# Minimal incremental unit is the smallest allowed step_size. Note: If extensive search True then minimal increment is set to 1\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     22\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124madd_first_last_points\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28;01mTrue\u001B[39;00m  \u001B[38;5;66;03m# Add first point and the last point the modified intervals\u001B[39;00m\n\u001B[1;32m     23\u001B[0m        }\n\u001B[1;32m     25\u001B[0m \u001B[38;5;66;03m# Validator Function Settings\u001B[39;00m\n\u001B[1;32m     26\u001B[0m \u001B[38;5;66;03m# For each fitted function we calculate Mean squared error(MSE):\u001B[39;00m\n\u001B[1;32m     27\u001B[0m \u001B[38;5;66;03m# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html\u001B[39;00m\n\u001B[1;32m     28\u001B[0m \u001B[38;5;66;03m# MSE ( (y_values, current_y_pred) + penality_weight * np.sum(current_coeff[:-1] ** 2) ) and compare it to the previous\u001B[39;00m\n\u001B[1;32m     29\u001B[0m \u001B[38;5;66;03m# We consider improvement acceptable if: (previous_mse - current_mse) >= improvement_threshold\u001B[39;00m\n\u001B[1;32m     30\u001B[0m vfs \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mthreshold_y_fitting\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m15\u001B[39m,  \u001B[38;5;66;03m# Threshold on the y axis\u001B[39;00m\n\u001B[1;32m     31\u001B[0m        \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mthreshold_x_interval\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m0.80\u001B[39m,  \u001B[38;5;66;03m# For unfit point expand by threshold_x_interval to each side to close unfit interval\u001B[39;00m\n\u001B[1;32m     32\u001B[0m        \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdegree\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m2\u001B[39m,  \u001B[38;5;66;03m# Minimum degree for exploration. We start with polyfit in x^degree\u001B[39;00m\n\u001B[1;32m     33\u001B[0m        \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmax_deg\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m9\u001B[39m,  \u001B[38;5;66;03m# Max degree for exploration to which degree we try to fit function x^max_degree\u001B[39;00m\n\u001B[1;32m     34\u001B[0m        \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mearly_stop\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;28;01mTrue\u001B[39;00m,  \u001B[38;5;66;03m# if early_stop = True and improvement is not acceptable by increasing dimension, we stop\u001B[39;00m\n\u001B[1;32m     35\u001B[0m        \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mimprovement_threshold\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m0.1\u001B[39m,  \u001B[38;5;66;03m# Sufficient improvement threshold (previous_mse - current_mse) >= improvement_threshold\u001B[39;00m\n\u001B[1;32m     36\u001B[0m        \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpenality_weight\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m1\u001B[39m,  \u001B[38;5;66;03m# Penalty for MSE to avoid overfitting with high dimension polynomial\u001B[39;00m\n\u001B[1;32m     37\u001B[0m        \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mx_labels\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTraffic volume [veh/h]\u001B[39m\u001B[38;5;124m'\u001B[39m,  \u001B[38;5;66;03m# Y axis label name validator graph\u001B[39;00m\n\u001B[1;32m     38\u001B[0m        \u001B[38;5;124m'\u001B[39m\u001B[38;5;124my_labels\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTTS [veh$\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mcdot$h]\u001B[39m\u001B[38;5;124m'\u001B[39m,  \u001B[38;5;66;03m# Y axis label name validator graph\u001B[39;00m\n\u001B[0;32m---> 39\u001B[0m        \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtitle\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFitted Curve with unfit Intervals for \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menviron\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mINSTANCE_NAME\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m,  \u001B[38;5;66;03m# Title for validator graph\u001B[39;00m\n\u001B[1;32m     40\u001B[0m        \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfigsize_x\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m12\u001B[39m,  \u001B[38;5;66;03m# X size of the figure\u001B[39;00m\n\u001B[1;32m     41\u001B[0m        \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfigsize_y\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m6\u001B[39m,  \u001B[38;5;66;03m# Y size of the figure\u001B[39;00m\n\u001B[1;32m     42\u001B[0m        \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfont_size\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m12\u001B[39m  \u001B[38;5;66;03m# Fontsize in the figure\u001B[39;00m\n\u001B[1;32m     43\u001B[0m        }\n\u001B[1;32m     45\u001B[0m \u001B[38;5;66;03m# Overall plot settings (the last plot with all the functions)\u001B[39;00m\n\u001B[1;32m     46\u001B[0m ops \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m     47\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mx_labels\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTraffic volume [veh/h]\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m     48\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124my_labels\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTTS [veh$\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mcdot$h]\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     57\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msigmoid_tailing\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;28;01mTrue\u001B[39;00m   \u001B[38;5;66;03m# Enable sigmoid tailing\u001B[39;00m\n\u001B[1;32m     58\u001B[0m     }\n",
      "File \u001B[0;32m/usr/lib/python3.10/os.py:680\u001B[0m, in \u001B[0;36m_Environ.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m    677\u001B[0m     value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_data[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mencodekey(key)]\n\u001B[1;32m    678\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m:\n\u001B[1;32m    679\u001B[0m     \u001B[38;5;66;03m# raise KeyError with the original key value\u001B[39;00m\n\u001B[0;32m--> 680\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    681\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdecodevalue(value)\n",
      "\u001B[0;31mKeyError\u001B[0m: 'INSTANCE_NAME'"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "b6e1719dfdd9a466",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
